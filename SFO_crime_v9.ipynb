{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2015-05-13 23:53:00' 'WARRANT ARREST' 'Wednesday' 'NORTHERN'\n",
      "  'ARREST, BOOKED' 'OAK ST / LAGUNA ST' -122.425891675136 37.7745985956747\n",
      "  4510.0]]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../train.csv\")\n",
    "\n",
    "v_datetime = pd.to_datetime(data_df['Dates'])\n",
    "v_date = v_datetime.dt.date\n",
    "v_date_diff = (v_date - v_date.min())/np.timedelta64(1, 'D')\n",
    "data_df['DateDiff'] = v_date_diff\n",
    "\n",
    "crime_data = np.array(data_df[['Dates', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y', 'DateDiff']].values)\n",
    "crime_labels = np.array(data_df[['Category']].values.ravel())\n",
    "print crime_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0L '2015-05-10 23:59:00' 'Sunday' 'BAYVIEW' '2000 Block of THOMAS AV'\n",
      "  -122.39958770418998 37.7350510103906 4512.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Id', 'Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y',\n",
       "       'DateDiff'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = pd.read_csv(\"../test.csv\")\n",
    "\n",
    "v_datetime = pd.to_datetime(test_data_df['Dates'])\n",
    "v_date = v_datetime.dt.date\n",
    "v_date_diff = (v_date - v_date.min())/np.timedelta64(1, 'D')\n",
    "test_data_df['DateDiff'] = v_date_diff\n",
    "\n",
    "test_data = np.array(test_data_df.values)\n",
    "print test_data[:1]\n",
    "test_data_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-13 23:53:00\n",
      "[2015, 5, 13, 1433.0, 23, 'Night']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def convert_date(date_val):\n",
    "    date_list = []\n",
    "    date, time = date_val.split()\n",
    "    date_list.append(int(date.split('-')[0]))\n",
    "    date_list.append(int(date.split('-')[1]))\n",
    "    date_list.append(int(date.split('-')[2]))\n",
    "    time_in_min = int(time.split(':')[0]) * 60.0 + int(time.split(':')[1])\n",
    "    date_list.append(time_in_min)\n",
    "    date_list.append(int(time.split(':')[0]))\n",
    "    time_hour = int(time.split(':')[0])\n",
    "    if time_hour < 6:\n",
    "        time_of_day = 'Twilight'\n",
    "    elif time_hour < 12:\n",
    "        time_of_day = 'Morning'\n",
    "    elif time_hour < 18:\n",
    "        time_of_day = 'Afternoon'\n",
    "    else:\n",
    "        time_of_day = 'Night'\n",
    "    date_list.append(time_of_day)\n",
    "    return date_list\n",
    "\n",
    "print crime_data[0][0]\n",
    "print convert_date(crime_data[0][0])\n",
    "\n",
    "def find_mean_std(train_data, index):\n",
    "    data = []\n",
    "    for row in train_data:\n",
    "        data.append(float(row[index]))\n",
    "    \n",
    "    data_arr = np.array(data, dtype=np.float32)\n",
    "    print np.mean(data_arr)\n",
    "    data_dict = {}\n",
    "    data_dict['mean'] = np.mean(data_arr)\n",
    "    data_dict['std'] = np.std(data_arr)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts = ['NORTHERN', 'PARK', 'INGLESIDE', 'BAYVIEW', 'RICHMOND', 'CENTRAL', 'TARAVAL', 'TENDERLOIN', 'MISSION', 'SOUTHERN']\n",
    "week_day = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daytime = ['Twilight', 'Morning', 'Afternoon', 'Night']\n",
    "year_range = ['2003-2006', '2006-2009', '2009-2012', 'After 2015']\n",
    "crime_year = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n",
    "crime_month = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "crime_day = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29 ,30 ,31]\n",
    "crime_hour = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-122.423\n",
      "37.771\n"
     ]
    }
   ],
   "source": [
    "''' Longitude & Latitude - Normalization '''\n",
    "long_dict = find_mean_std(crime_data, 6)\n",
    "lat_dict = find_mean_std(crime_data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrimeX Data shape:  (878049L, 93L)\n",
      "CrimeX Label shape:  (878049L,)\n",
      "[[   0.        1.        0.        0.        0.        0.        1.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        1.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.        0.        0.        1.        0.        0.        0.\n",
      "     1.        0.        0.        1.        0.        0.        0.        0.\n",
      "     1.        0.        0.        0.        0.        0.        0.        0.\n",
      "     0.        0.     -122.426    37.775  -122.4259]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_formatted_data(train_data):\n",
    "    format_data = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(train_data)):\n",
    "        count += 1\n",
    "        data = []\n",
    "        row = train_data[i]\n",
    "        \n",
    "        ''' Data Preparation - Crime date '''\n",
    "        \n",
    "        #date_list = convert_date(row[0])\n",
    "        # [2015, 5, 13, 1433.0, 23, 'Night']\n",
    "        \n",
    "        date_arr = convert_date(row[0])\n",
    "        year, month, day, time_in_min, hour, time_of_day = date_arr\n",
    "        \n",
    "        norm_year = [(year < 2010)*1, (year>=2010)*1]\n",
    "        data.extend(norm_year)\n",
    "        \n",
    "        norm_month = [1 if month == m else 0 for m in crime_month]\n",
    "        data.extend(norm_month)\n",
    "        \n",
    "        norm_day = [1 if day == d else 0 for d in crime_day]\n",
    "        data.extend(norm_day)\n",
    "        \n",
    "        norm_hour = [1 if hour == h else 0 for h in crime_hour]\n",
    "        data.extend(norm_hour)\n",
    "        \n",
    "        # Time of the day preparation\n",
    "        day_time = [1 if time_of_day == td else 0 for td in daytime]\n",
    "        data.extend(day_time)\n",
    "        \n",
    "        \n",
    "        ''' Data Preparation - Day of the Week '''\n",
    "        wk_day = row[2]\n",
    "        \n",
    "        crime_week_day = [1 if wk_day == d else 0 for d in week_day] \n",
    "        data.extend(crime_week_day) # Normalized\n",
    "        \n",
    "        ''' Data Preparation - District '''\n",
    "        pdd = row[3]\n",
    "        pddistrict = [1 if pdd == d else 0 for d in districts] # Normalized\n",
    "        data.extend(pddistrict)\n",
    "        \n",
    "        ''' Data Preparation - Longitude & Latitude '''\n",
    "        '''\n",
    "        longitude = float(row[6])\n",
    "        long_norm = (abs(longitude) - abs(long_dict['mean']))/long_dict['std'] # Normalized\n",
    "        latitude = float(row[7])\n",
    "        lat_norm = (abs(latitude) - abs(lat_dict['mean']))/lat_dict['std'] # Normalized\n",
    "        '''\n",
    "        \n",
    "        long_norm = round(row[6],3)\n",
    "        lat_norm = round(row[7], 3)\n",
    "        \n",
    "        #long_norm = round(row[6],3)\n",
    "        #lat_norm = round(float(row[7]), 3)\n",
    "        data.append(long_norm)\n",
    "        data.append(lat_norm)\n",
    "        \n",
    "        #cluster_label = cl_index[i]\n",
    "        #data.append(cluster_label)\n",
    "        \n",
    "        ''' Data Preparation - Address '''\n",
    "        \n",
    "        #address = row[5].lower()\n",
    "        #addr = [1 if 'block' in address else 0] # Requires major improvement\n",
    "        #data.extend(addr)\n",
    "        \n",
    "        date_diff = round(row[6], 4)\n",
    "        data.append(date_diff)\n",
    "        \n",
    "        ''' Quantify the data '''\n",
    "        format_data.append(np.array(data))           \n",
    "        \n",
    "    return format_data\n",
    "    \n",
    "    \n",
    "crimeX = np.array(get_formatted_data(crime_data))\n",
    "print \"CrimeX Data shape: \", crimeX.shape\n",
    "print \"CrimeX Label shape: \", np.array(crime_labels).shape\n",
    "print crimeX[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-122.426\n"
     ]
    }
   ],
   "source": [
    "long_norm = -122.4260025\n",
    "print round(long_norm, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y, seed=1337):\n",
    "  np.random.seed(seed)\n",
    "  shuffle = np.arange(len(y))\n",
    "  np.random.shuffle(shuffle)\n",
    "  X = X[shuffle]\n",
    "  y = y[shuffle]\n",
    "  return X, y\n",
    "\n",
    "crimeX, crime_labels = shuffle(crimeX, crime_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_trainX, mini_train_labels = crimeX[:200000], crime_labels[:200000]\n",
    "mini_testX, mini_test_labels = crimeX[200000:400000], crime_labels[200000:400000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for Logistic Regression:  {'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\sklearn\\cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.001, 0.01, 0.1, 0.2, 1, 10, 100]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), params)\n",
    "clf.fit(mini_trainX[:10000], mini_train_labels[:10000])\n",
    "print \"Best Params for Logistic Regression: \", clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:960: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training with best C\n",
      "Logistic Regression Results\n",
      "--------------------\n",
      "Accuracy:  0.19537\n",
      "Log Loss:  2.70455706744\n",
      "F1 Score:  0.32687787045\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', C=0.01, tol=0.01)\n",
    "clf.fit(mini_trainX, mini_train_labels)\n",
    "print \"Completed training with best C\"\n",
    "clf_accuracy = clf.score(mini_testX, mini_test_labels)\n",
    "clf_probs = clf.predict_proba(mini_testX)\n",
    "clf_log_loss = log_loss(mini_test_labels, clf_probs)\n",
    "f1_score = metrics.f1_score(clf.predict(mini_testX), mini_test_labels)\n",
    "\n",
    "print \"Logistic Regression Results\"\n",
    "print \"--------------------\"\n",
    "print \"Accuracy: \", clf_accuracy\n",
    "print \"Log Loss: \", clf_log_loss\n",
    "print \"F1 Score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training with best C\n",
      "Logistic Regression Results\n",
      "--------------------\n",
      "Accuracy:  0.225155\n",
      "Log Loss:  7.35380556788\n",
      "F1 Score:  0.278253872726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=39)\n",
    "clf.fit(mini_trainX, mini_train_labels)\n",
    "print \"Completed training with best C\"\n",
    "clf_accuracy = clf.score(mini_testX, mini_test_labels)\n",
    "clf_probs = clf.predict_proba(mini_testX)\n",
    "clf_log_loss = log_loss(mini_test_labels, clf_probs)\n",
    "f1_score = metrics.f1_score(clf.predict(mini_testX), mini_test_labels)\n",
    "\n",
    "print \"Random Forest Results\"\n",
    "print \"--------------------\"\n",
    "print \"Accuracy: \", clf_accuracy\n",
    "print \"Log Loss: \", clf_log_loss\n",
    "print \"F1 Score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training with best C\n",
      "BernoulliNB Results\n",
      "--------------------\n",
      "Accuracy:  0.19025\n",
      "Log Loss:  3.03587210942\n",
      "F1 Score:  0.236026844657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(mini_trainX, mini_train_labels)\n",
    "print \"Completed training with best C\"\n",
    "clf_accuracy = clf.score(mini_testX, mini_test_labels)\n",
    "clf_probs = clf.predict_proba(mini_testX)\n",
    "clf_log_loss = log_loss(mini_test_labels, clf_probs)\n",
    "f1_score = metrics.f1_score(clf.predict(mini_testX), mini_test_labels)\n",
    "\n",
    "print \"BernoulliNB Results\"\n",
    "print \"--------------------\"\n",
    "print \"Accuracy: \", clf_accuracy\n",
    "print \"Log Loss: \", clf_log_loss\n",
    "print \"F1 Score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_formatted_test_data(test_data):\n",
    "    format_data = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        count += 1\n",
    "        data = []\n",
    "        \n",
    "        row = test_data[i]\n",
    "        \n",
    "        ''' Data Preparation - Date '''\n",
    "        date_arr = convert_date(row[1])\n",
    "        year, month, day, time_in_min, hour, time_of_day = date_arr\n",
    "        \n",
    "        #norm_year = [1 if year == y else 0 for y in crime_year]\n",
    "        norm_year = [(year < 2010)*1, (year>=2010)*1]\n",
    "        data.extend(norm_year)\n",
    "        \n",
    "        norm_month = [1 if month == m else 0 for m in crime_month]\n",
    "        data.extend(norm_month)\n",
    "        \n",
    "        norm_day = [1 if day == d else 0 for d in crime_day]\n",
    "        data.extend(norm_day)\n",
    "        \n",
    "        norm_hour = [1 if hour == h else 0 for h in crime_hour]\n",
    "        data.extend(norm_hour)\n",
    "        \n",
    "        # Time of the day preparation\n",
    "        day_time = [1 if time_of_day == td else 0 for td in daytime]\n",
    "        data.extend(day_time)\n",
    "        \n",
    "        ''' Data Preparation - Day of the Week '''\n",
    "        wk_day = row[2]\n",
    "        \n",
    "        crime_week_day = [1 if wk_day == d else 0 for d in week_day] \n",
    "        data.extend(crime_week_day) # Normalized\n",
    "        \n",
    "        pdd = row[3]\n",
    "        pddistrict = [1 if pdd == d else 0 for d in districts]\n",
    "        data.extend(pddistrict)\n",
    "        \n",
    "        longitude = float(row[5])\n",
    "        long_norm = (abs(longitude) - abs(long_dict['mean']))/long_dict['std']\n",
    "        latitude = float(row[6])\n",
    "        lat_norm = (abs(latitude) - abs(lat_dict['mean']))/lat_dict['std']\n",
    "        data.append(long_norm)\n",
    "        data.append(lat_norm)\n",
    "        \n",
    "        #test_cluster_label = clt_index[i]\n",
    "        #data.append(test_cluster_label)\n",
    "        \n",
    "        address = row[4].lower()\n",
    "        addr = [1 if 'block' in address else 0]\n",
    "        data.extend(addr)\n",
    "        \n",
    "        date_diff = row[5]\n",
    "        data.append(date_diff)\n",
    "        \n",
    "        format_data.append(np.array(data, dtype=np.float32))    \n",
    "        \n",
    "        \n",
    "        \n",
    "    return format_data\n",
    "    \n",
    "    \n",
    "\n",
    "testX = np.array(get_formatted_test_data(test_data), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d04379c98a0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrimeX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrime_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Completed the training\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=0.01, tol=0.01)\n",
    "lr.fit(crimeX, crime_labels)\n",
    "print \"Completed the training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d79575bc31d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "probs = lr.predict_proba(testX)\n",
    "print probs.shape\n",
    "print probs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job completed\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "with gzip.open('submission-matrix-5.csv.gz', 'wb') as f:\n",
    "    out = csv.writer(f, lineterminator='\\n')\n",
    "    out.writerow(['Id'] + list(np.unique(crime_labels)))\n",
    "    \n",
    "    for i, prob in enumerate(probs):\n",
    "        out.writerow([i] + list(prob))\n",
    "print \"Job completed\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_features(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['Dates'])\n",
    "    date_vector = data['DateTime'].dt.date\n",
    "    data['DateDiff'] = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    data['Year'] = pd.DatetimeIndex(data['DateTime']).year\n",
    "    data['Month'] = pd.DatetimeIndex(data['DateTime']).month\n",
    "    data['Day'] = pd.DatetimeIndex(data['DateTime']).day\n",
    "    data['Hour'] = pd.DatetimeIndex(data['DateTime']).hour\n",
    "    data['SecondsDelta'] = (data.DateTime - pd.Timestamp('2013-01-01')) / np.timedelta64(1,'s')\n",
    "    data['Weekend'] = (data.DayOfWeek == \"Saturday\") | (data.DayOfWeek == \"Sunday\")\n",
    "    years = pd.get_dummies(data.Year)\n",
    "    years.columns = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "    months = pd.get_dummies(data.Month)\n",
    "    months.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    days = pd.get_dummies(data.Day)\n",
    "    days.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    daysofweek = pd.get_dummies(data.DayOfWeek)\n",
    "    hours = pd.get_dummies(data.Hour)\n",
    "    hours.columns = ['12AM', '1AM', '2AM', '3AM', '4AM', '5AM',\n",
    "                     '6AM', '7AM', '8AM', '9AM', '10AM', '11AM',\n",
    "                     '12PM', '1PM', '2PM', '3PM', '4PM', '5PM',\n",
    "                     '6PM', '7PM', '8PM', '9PM', '10PM', '11PM']\n",
    "    districts = pd.get_dummies(data.PdDistrict)\n",
    "    new_data = pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "    return new_data\n",
    "\n",
    "data = build_features(data_df)\n",
    "test = build_features(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 147)\n",
      "(878049, 107)\n",
      "\n",
      "(884262, 147)\n",
      "(884262, 107)\n"
     ]
    }
   ],
   "source": [
    "# Generate location-based dummies\n",
    "XR3 = data['X'].round(decimals=3).apply(str)\n",
    "YR3 = data['Y'].round(decimals=3).apply(str)\n",
    "data_XR3s = pd.get_dummies(XR3)\n",
    "data_YR3s = pd.get_dummies(YR3)    \n",
    "XR3 = test['X'].round(decimals=3).apply(str)\n",
    "YR3 = test['Y'].round(decimals=3).apply(str)\n",
    "test_XR3s = pd.get_dummies(XR3)\n",
    "test_YR3s = pd.get_dummies(YR3)    \n",
    "\n",
    "#Subset the test to only include features that exist in training set\n",
    "test_XR3s = test_XR3s[list(data_XR3s)]\n",
    "test_YR3s = test_YR3s[list(data_YR3s)]\n",
    "\n",
    "print data_XR3s.shape\n",
    "print data_YR3s.shape\n",
    "print\n",
    "print test_XR3s.shape\n",
    "print test_YR3s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "train_labels = data.Category\n",
    "\n",
    "# Create integer labels\n",
    "panda_labels = pd.Categorical(data.Category).codes\n",
    "train_labels_int = np.array(panda_labels).astype(np.int32)\n",
    "\n",
    "# Drop Category, Descript and Resolution columns since they are not in the test set.\n",
    "# Drop non-numerics too - they are accounted for as dummy variables.\n",
    "train_data = data.drop(['Category', 'Descript', 'Resolution', 'DateTime', 'Dates', 'PdDistrict', 'Address', 'DayOfWeek'], axis=1)\n",
    "train_data.Weekend = train_data.Weekend * 1\n",
    "train_names = train_data.columns.values.tolist()\n",
    "\n",
    "test_data = test.drop(['DateTime', 'Dates', 'PdDistrict', 'Address', 'DayOfWeek'], axis=1)\n",
    "test_data.Weekend = test_data.Weekend * 1\n",
    "test_names = test_data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-28fcce991afc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Jan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Friday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Monday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Saturday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sunday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Thursday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tuesday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Wednesday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'12AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'4AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'6AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'7AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'8AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'9AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'10AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'11AM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'12PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'4PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'6PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'7PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'8PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'9PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'10PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'11PM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BAYVIEW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CENTRAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'INGLESIDE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MISSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NORTHERN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PARK'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RICHMOND'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SOUTHERN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TARAVAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TENDERLOIN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYear\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2006\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYear\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2008\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYear\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2010\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_XR3s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_YR3s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.values_from_object (pandas\\lib.c:4162)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2332\u001b[0m         \u001b[1;34m\"\"\" same as values (but handles sparseness conversions) \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2333\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m   2302\u001b[0m         \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2303\u001b[0m         \"\"\"\n\u001b[1;32m-> 2304\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2199\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2200\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2201\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   2190\u001b[0m         \u001b[1;34m\"\"\" consolidate _data. if the blocks have changed, then clear the cache \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2198\u001b[0m         \u001b[1;34m\"\"\" we are inplace consolidating; return None \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2200\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2832\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2833\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2834\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2835\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2839\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2840\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2841\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   3819\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3820\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[1;32m-> 3821\u001b[1;33m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[0;32m   3822\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3823\u001b[0m             \u001b[0mnew_blocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3842\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3843\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3844\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3846\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_vstack\u001b[1;34m(to_stack, dtype)\u001b[0m\n\u001b[0;32m   3872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3873\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3874\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pgundugola\\Downloads\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\numpy\\core\\shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \"\"\"\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['Jan','Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2006) * 1, (data.Year < 2008) * 1, (data.Year < 2010) * 1, data_XR3s, data_YR3s], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_test_data = np.array(pd.concat([test_data[features], (test.Year < 2006) * 1, (test.Year < 2008) * 1, (test.Year < 2010) * 1, test_XR3s[list(data_XR3s)], test_YR3s[list(data_YR3s)]], axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
